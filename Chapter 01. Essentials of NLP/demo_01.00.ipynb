{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Đọc dữ liệu ko có định dạng rõ ràng."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "lines = io.open(\"./data/smsspamcollection/SMSSpamCollection\").read().strip().split('\\n')\n",
    "\n",
    "lines[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Tách các label và text ra, đồng thời gán giá trị $1$ cho `spam` và $0$ cho `ham`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "spam_dataset = []\n",
    "\n",
    "for line in lines:\n",
    "    label, text = line.split('\\t')\n",
    "    \n",
    "    if label.strip() == 'spam':\n",
    "        spam_dataset.append((1, text.strip()))\n",
    "    else:\n",
    "        spam_dataset.append((0, text.strip()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "spam_dataset[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0,\n",
       " 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "len(spam_dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = pd.DataFrame(spam_dataset, columns=['Spam', 'Message'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def message_length(x):\n",
    "    return len(x)\n",
    "\n",
    "def num_capitals(x):\n",
    "    _, count = re.subn(r\"[A-Z]\", \"\", x)\n",
    "    return count\n",
    "\n",
    "def num_punctuation(x):\n",
    "    _, count = re.subn(r\"\\W\", \"\", x)\n",
    "    return count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df['Capitals'] = df['Message'].apply(num_capitals)\n",
    "df['Punctuation'] = df['Message'].apply(num_punctuation)\n",
    "df['Length'] = df[\"Message\"].apply(message_length)\n",
    "\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Spam     Capitals  Punctuation       Length\n",
       "count  5574.000000  5574.000000  5574.000000  5574.000000\n",
       "mean      0.134015     5.621636    18.942591    80.443488\n",
       "std       0.340699    11.683233    14.825994    59.841746\n",
       "min       0.000000     0.000000     0.000000     2.000000\n",
       "25%       0.000000     1.000000     8.000000    36.000000\n",
       "50%       0.000000     2.000000    15.000000    61.000000\n",
       "75%       0.000000     4.000000    27.000000   122.000000\n",
       "max       1.000000   129.000000   253.000000   910.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "      <td>5574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.134015</td>\n",
       "      <td>5.621636</td>\n",
       "      <td>18.942591</td>\n",
       "      <td>80.443488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340699</td>\n",
       "      <td>11.683233</td>\n",
       "      <td>14.825994</td>\n",
       "      <td>59.841746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>910.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Chia dữ liệu thành train data và test data với kích thước 80% và 20%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "x_train = train[['Length', 'Capitals', 'Punctuation']]\n",
    "y_train = train[['Spam']]\n",
    "\n",
    "x_test = test[['Length', 'Capitals', 'Punctuation']]\n",
    "y_test = test[['Spam']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling normalized data\n",
    "* Model sẽ sử dụng binary cross-entropy để tính toán loss value và Adam optimizer để train data.\n",
    "* MOdel dc build dựa trên 3 feature là `Length`, `Capitals` và `Punctuation`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def make_model(input_dims=3, num_units=12):\n",
    "    \"\"\"\n",
    "    Dùng để build model\n",
    "\n",
    "    Args:\n",
    "        input_dims (int, optional): Số feature có trong input.\n",
    "        num_units (int, optional): [description]. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    '''Thêm một layer được kết nối với 12 unit của model'''\n",
    "    model.add(tf.keras.layers.Dense(num_units,\n",
    "                                    input_dim=input_dims,\n",
    "                                    activation='relu'))\n",
    "    \n",
    "    '''Thêm một sigmoid layer với binary output unit'''\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = make_model()\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 1s 725us/step - loss: 0.5489 - accuracy: 0.8823\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s 921us/step - loss: 0.3178 - accuracy: 0.9054\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s 674us/step - loss: 0.2585 - accuracy: 0.9199\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s 718us/step - loss: 0.2384 - accuracy: 0.9224\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s 694us/step - loss: 0.2290 - accuracy: 0.9217\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9199\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2291 - accuracy: 0.9199\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2156 - accuracy: 0.9242\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s 779us/step - loss: 0.2151 - accuracy: 0.9244\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s 999us/step - loss: 0.2212 - accuracy: 0.9231\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc28808cd90>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9238\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.20615598559379578, 0.9237667918205261]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "y_train_pred = model.predict_classes(x_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/manhcuong/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tf.math.confusion_matrix(tf.constant(y_train.Spam), y_train_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[3781,   86],\n",
       "       [ 221,  371]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization\n",
    "* Có thể xem các ngôn ngữ mà `stanfordnlp` hỗ trợ tokenization tại [https://stanfordnlp.github.io/stanfordnlp/models.html](https://stanfordnlp.github.io/stanfordnlp/models.html)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import stanfordnlp as snlp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "vi = snlp.download('vi')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using the default treebank \"vi_vtb\" for language \"vi\".\n",
      "Would you like to download the models for: vi_vtb now? (Y/n)\n",
      "\n",
      "Default download directory: /home/manhcuong/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "Downloading models for: vi_vtb\n",
      "Download location: /home/manhcuong/stanfordnlp_resources/vi_vtb_models.zip\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 217M/217M [00:52<00:00, 4.13MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Download complete.  Models saved to: /home/manhcuong/stanfordnlp_resources/vi_vtb_models.zip\n",
      "Extracting models file for: vi_vtb\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "en = snlp.download('en')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "\n",
      "Default download directory: /home/manhcuong/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: /home/manhcuong/stanfordnlp_resources/en_ewt_models.zip\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 235M/235M [00:57<00:00, 4.09MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Download complete.  Models saved to: /home/manhcuong/stanfordnlp_resources/en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "vi = snlp.Pipeline(lang='vi', processors='tokenize')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/manhcuong/stanfordnlp_resources/vi_vtb_models/vi_vtb_tokenizer.pt', 'lang': 'vi', 'shorthand': 'vi_vtb', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "sentence = \"Có con đường nào bước qua ta đến mang em món quà hẹn hò yêu thương ta say đến già. Nắng mưa là chuyện nắng mưa, ai biết yêu thương đã vừa...\"\n",
    "tokenized = vi(sentence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "len(tokenized.sentences)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> * `sentence` gồm 2 câu, câu 1 bắt đầu từ \"Có con đường... đến già.\". Câu hai là \"Nắng mưa... đã vừa...\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "for snt in tokenized.sentences:\n",
    "    for word in snt.tokens:\n",
    "        print(word.text)\n",
    "        \n",
    "    print(\"<End of Sentence>\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Có\n",
      "con\n",
      "đường\n",
      "nào\n",
      "bước\n",
      "qua ta\n",
      "đến\n",
      "mang\n",
      "em\n",
      "món\n",
      "quà\n",
      "hẹn\n",
      "hò\n",
      "yêu\n",
      "thương\n",
      "ta\n",
      "say\n",
      "đến\n",
      "già\n",
      ".\n",
      "<End of Sentence>\n",
      "Nắng\n",
      "mưa\n",
      "là\n",
      "chuyện\n",
      "nắng mưa\n",
      ",\n",
      "ai\n",
      "biết\n",
      "yêu thương\n",
      "đã\n",
      "vừa\n",
      "...\n",
      "<End of Sentence>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "en = snlp.Pipeline(lang='en', processors='tokenize')\n",
    "\n",
    "def word_counts(x, pipeline=en):\n",
    "    \"\"\"\n",
    "    Dùng để đếm số từ trong `x`\n",
    "    \"\"\"\n",
    "    doc = pipeline(x)\n",
    "    count = sum([len(sentence.tokens) for sentence in doc.sentences])\n",
    "    \n",
    "    return count"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/manhcuong/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "train['Words'] = train['Message'].apply(word_counts)\n",
    "test['Words'] = test['Message'].apply(word_counts)\n",
    "\n",
    "x_train = train[['Words', 'Capitals', 'Punctuation', 'Length']]\n",
    "y_train = train[['Spam']]\n",
    "\n",
    "x_test = test[['Words', 'Capitals', 'Punctuation', 'Length']]\n",
    "y_test = test[['Spam']]\n",
    "\n",
    "model = make_model(input_dims=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.3019 - accuracy: 0.9231\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.9291\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2283 - accuracy: 0.9298\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2109 - accuracy: 0.9327\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2147 - accuracy: 0.9296\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2010 - accuracy: 0.9309\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9329\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2194e8d90>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "train.loc[train.Spam == 1].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Spam    Capitals  Punctuation      Length       Words\n",
       "count  592.0  592.000000   592.000000  592.000000  592.000000\n",
       "mean     1.0   15.320946    29.086149  138.856419   29.511824\n",
       "std      0.0   11.635105     7.083572   28.079980    7.474256\n",
       "min      1.0    0.000000     2.000000   13.000000    3.000000\n",
       "25%      1.0    7.000000    26.000000  132.000000   26.000000\n",
       "50%      1.0   14.000000    30.000000  149.000000   30.000000\n",
       "75%      1.0   21.000000    34.000000  157.000000   35.000000\n",
       "max      1.0  128.000000    49.000000  197.000000   49.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.0</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.320946</td>\n",
       "      <td>29.086149</td>\n",
       "      <td>138.856419</td>\n",
       "      <td>29.511824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.635105</td>\n",
       "      <td>7.083572</td>\n",
       "      <td>28.079980</td>\n",
       "      <td>7.474256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "train.loc[train.Spam == 0].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Spam     Capitals  Punctuation       Length        Words\n",
       "count  3867.0  3867.000000  3867.000000  3867.000000  3867.000000\n",
       "mean      0.0     4.018878    17.325058    71.354538    17.344194\n",
       "std       0.0    10.599291    14.826644    57.755351    13.811278\n",
       "min       0.0     0.000000     0.000000     2.000000     1.000000\n",
       "25%       0.0     1.000000     8.000000    33.000000     8.000000\n",
       "50%       0.0     2.000000    13.000000    53.000000    13.000000\n",
       "75%       0.0     3.000000    23.000000    92.000000    22.000000\n",
       "max       0.0   129.000000   253.000000   910.000000   209.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3867.0</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018878</td>\n",
       "      <td>17.325058</td>\n",
       "      <td>71.354538</td>\n",
       "      <td>17.344194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.599291</td>\n",
       "      <td>14.826644</td>\n",
       "      <td>57.755351</td>\n",
       "      <td>13.811278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>209.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import stopwordsiso as stopwords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "vi_sw = stopwords.stopwords('vi')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "len(vi_sw)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "vi_sw"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'a ha',\n",
       " 'a-lô',\n",
       " 'ai',\n",
       " 'ai ai',\n",
       " 'ai nấy',\n",
       " 'alô',\n",
       " 'amen',\n",
       " 'anh',\n",
       " 'bao giờ',\n",
       " 'bao lâu',\n",
       " 'bao nhiêu',\n",
       " 'bao nả',\n",
       " 'bay biến',\n",
       " 'biết',\n",
       " 'biết bao',\n",
       " 'biết bao nhiêu',\n",
       " 'biết chừng nào',\n",
       " 'biết mấy',\n",
       " 'biết đâu',\n",
       " 'biết đâu chừng',\n",
       " 'biết đâu đấy',\n",
       " 'bà',\n",
       " 'bài',\n",
       " 'bác',\n",
       " 'bây bẩy',\n",
       " 'bây chừ',\n",
       " 'bây giờ',\n",
       " 'bây nhiêu',\n",
       " 'bèn',\n",
       " 'béng',\n",
       " 'bông',\n",
       " 'bạn',\n",
       " 'bản',\n",
       " 'bất chợt',\n",
       " 'bất cứ',\n",
       " 'bất giác',\n",
       " 'bất kì',\n",
       " 'bất kể',\n",
       " 'bất kỳ',\n",
       " 'bất luận',\n",
       " 'bất nhược',\n",
       " 'bất quá',\n",
       " 'bất thình lình',\n",
       " 'bất tử',\n",
       " 'bất đồ',\n",
       " 'bấy',\n",
       " 'bấy chầy',\n",
       " 'bấy chừ',\n",
       " 'bấy giờ',\n",
       " 'bấy lâu',\n",
       " 'bấy lâu nay',\n",
       " 'bấy nay',\n",
       " 'bấy nhiêu',\n",
       " 'bập bà bập bõm',\n",
       " 'bập bõm',\n",
       " 'bắt đầu từ',\n",
       " 'bằng',\n",
       " 'bằng không',\n",
       " 'bằng nấy',\n",
       " 'bằng ấy',\n",
       " 'bển',\n",
       " 'bệt',\n",
       " 'bị',\n",
       " 'bỏ mẹ',\n",
       " 'bỗng',\n",
       " 'bỗng chốc',\n",
       " 'bỗng dưng',\n",
       " 'bỗng không',\n",
       " 'bỗng nhiên',\n",
       " 'bỗng đâu',\n",
       " 'bộ',\n",
       " 'bội phần',\n",
       " 'bớ',\n",
       " 'bởi',\n",
       " 'bởi chưng',\n",
       " 'bởi nhưng',\n",
       " 'bởi thế',\n",
       " 'bởi vì',\n",
       " 'bởi vậy',\n",
       " 'bức',\n",
       " 'cao',\n",
       " 'cha',\n",
       " 'cha chả',\n",
       " 'chao ôi',\n",
       " 'chiếc',\n",
       " 'cho',\n",
       " 'cho nên',\n",
       " 'cho tới',\n",
       " 'cho tới khi',\n",
       " 'cho đến',\n",
       " 'cho đến khi',\n",
       " 'choa',\n",
       " 'chu cha',\n",
       " 'chui cha',\n",
       " 'chung cục',\n",
       " 'chung qui',\n",
       " 'chung quy',\n",
       " 'chung quy lại',\n",
       " 'chuyện',\n",
       " 'chành chạnh',\n",
       " 'chí chết',\n",
       " 'chính',\n",
       " 'chính là',\n",
       " 'chính thị',\n",
       " 'chùn chùn',\n",
       " 'chùn chũn',\n",
       " 'chú',\n",
       " 'chú mày',\n",
       " 'chú mình',\n",
       " 'chúng mình',\n",
       " 'chúng ta',\n",
       " 'chúng tôi',\n",
       " 'chăn chắn',\n",
       " 'chăng',\n",
       " 'chưa',\n",
       " 'chầm chập',\n",
       " 'chậc',\n",
       " 'chắc',\n",
       " 'chắc hẳn',\n",
       " 'chẳng lẽ',\n",
       " 'chẳng những',\n",
       " 'chẳng nữa',\n",
       " 'chẳng phải',\n",
       " 'chết nỗi',\n",
       " 'chết thật',\n",
       " 'chết tiệt',\n",
       " 'chỉ',\n",
       " 'chỉn',\n",
       " 'chốc chốc',\n",
       " 'chớ',\n",
       " 'chớ chi',\n",
       " 'chợt',\n",
       " 'chủn',\n",
       " 'chứ',\n",
       " 'chứ lị',\n",
       " 'coi bộ',\n",
       " 'coi mòi',\n",
       " 'con',\n",
       " 'cu cậu',\n",
       " 'cuốn',\n",
       " 'cuộc',\n",
       " 'càng',\n",
       " 'các',\n",
       " 'cái',\n",
       " 'cây',\n",
       " 'còn',\n",
       " 'có',\n",
       " 'có chăng là',\n",
       " 'có dễ',\n",
       " 'có thể',\n",
       " 'có vẻ',\n",
       " 'cóc khô',\n",
       " 'cô',\n",
       " 'cô mình',\n",
       " 'công nhiên',\n",
       " 'cùng',\n",
       " 'cùng cực',\n",
       " 'cùng nhau',\n",
       " 'cùng với',\n",
       " 'căn',\n",
       " 'căn cắt',\n",
       " 'cũng',\n",
       " 'cũng như',\n",
       " 'cũng vậy',\n",
       " 'cũng vậy thôi',\n",
       " 'cơ',\n",
       " 'cơ chừng',\n",
       " 'cơ hồ',\n",
       " 'cơ mà',\n",
       " 'cơn',\n",
       " 'cả',\n",
       " 'cả thảy',\n",
       " 'cả thể',\n",
       " 'cảm ơn',\n",
       " 'cần',\n",
       " 'cật lực',\n",
       " 'cật sức',\n",
       " 'cậu',\n",
       " 'cổ lai',\n",
       " 'của',\n",
       " 'cứ',\n",
       " 'cứ việc',\n",
       " 'cực lực',\n",
       " 'do',\n",
       " 'do vì',\n",
       " 'do vậy',\n",
       " 'do đó',\n",
       " 'duy',\n",
       " 'dào',\n",
       " 'dì',\n",
       " 'dù cho',\n",
       " 'dù rằng',\n",
       " 'dưới',\n",
       " 'dạ',\n",
       " 'dần dà',\n",
       " 'dần dần',\n",
       " 'dầu sao',\n",
       " 'dẫu',\n",
       " 'dẫu sao',\n",
       " 'dễ sợ',\n",
       " 'dễ thường',\n",
       " 'dở chừng',\n",
       " 'dữ',\n",
       " 'em',\n",
       " 'giữa',\n",
       " 'gì',\n",
       " 'hay',\n",
       " 'hoàn toàn',\n",
       " 'hoặc',\n",
       " 'hơn',\n",
       " 'hầu hết',\n",
       " 'họ',\n",
       " 'hỏi',\n",
       " 'khi',\n",
       " 'khác',\n",
       " 'không',\n",
       " 'luôn',\n",
       " 'là',\n",
       " 'làm',\n",
       " 'lên',\n",
       " 'lúc',\n",
       " 'lại',\n",
       " 'lần',\n",
       " 'lớn',\n",
       " 'muốn',\n",
       " 'mà',\n",
       " 'mình',\n",
       " 'mỗi',\n",
       " 'một',\n",
       " 'một cách',\n",
       " 'mới',\n",
       " 'mợ',\n",
       " 'ngay',\n",
       " 'ngay cả',\n",
       " 'ngay khi',\n",
       " 'ngay lúc',\n",
       " 'ngay lập tức',\n",
       " 'ngay tức khắc',\n",
       " 'ngay từ',\n",
       " 'nghe chừng',\n",
       " 'nghe đâu',\n",
       " 'nghen',\n",
       " 'nghiễm nhiên',\n",
       " 'nghỉm',\n",
       " 'ngoài',\n",
       " 'ngoài ra',\n",
       " 'ngoải',\n",
       " 'ngày',\n",
       " 'ngày càng',\n",
       " 'ngày ngày',\n",
       " 'ngày xưa',\n",
       " 'ngày xửa',\n",
       " 'ngôi',\n",
       " 'ngõ hầu',\n",
       " 'ngăn ngắt',\n",
       " 'ngươi',\n",
       " 'người',\n",
       " 'ngọn',\n",
       " 'ngọt',\n",
       " 'ngộ nhỡ',\n",
       " 'nh',\n",
       " 'nhau',\n",
       " 'nhiên hậu',\n",
       " 'nhiều',\n",
       " 'nhiệt liệt',\n",
       " 'nhung nhăng',\n",
       " 'nhà',\n",
       " 'nhân dịp',\n",
       " 'nhân tiện',\n",
       " 'nhé',\n",
       " 'nhón nhén',\n",
       " 'như',\n",
       " 'như chơi',\n",
       " 'như không',\n",
       " 'như quả',\n",
       " 'như thể',\n",
       " 'như tuồng',\n",
       " 'như vậy',\n",
       " 'nhưng',\n",
       " 'nhưng mà',\n",
       " 'nhược bằng',\n",
       " 'nhất',\n",
       " 'nhất loạt',\n",
       " 'nhất luật',\n",
       " 'nhất mực',\n",
       " 'nhất nhất',\n",
       " 'nhất quyết',\n",
       " 'nhất sinh',\n",
       " 'nhất thiết',\n",
       " 'nhất tâm',\n",
       " 'nhất tề',\n",
       " 'nhất đán',\n",
       " 'nhất định',\n",
       " 'nhận',\n",
       " 'nhỉ',\n",
       " 'nhỡ ra',\n",
       " 'những',\n",
       " 'những ai',\n",
       " 'những như',\n",
       " 'nào',\n",
       " 'này',\n",
       " 'nên',\n",
       " 'nên chi',\n",
       " 'nó',\n",
       " 'nóc',\n",
       " 'nói',\n",
       " 'năm',\n",
       " 'nơi',\n",
       " 'nấy',\n",
       " 'nếu',\n",
       " 'nếu như',\n",
       " 'nền',\n",
       " 'nọ',\n",
       " 'nớ',\n",
       " 'nức nở',\n",
       " 'nữa',\n",
       " 'oai oái',\n",
       " 'oái',\n",
       " 'pho',\n",
       " 'phè',\n",
       " 'phóc',\n",
       " 'phót',\n",
       " 'phăn phắt',\n",
       " 'phương chi',\n",
       " 'phải',\n",
       " 'phải chi',\n",
       " 'phải chăng',\n",
       " 'phắt',\n",
       " 'phỉ phui',\n",
       " 'phỏng',\n",
       " 'phỏng như',\n",
       " 'phốc',\n",
       " 'phụt',\n",
       " 'phứt',\n",
       " 'qua',\n",
       " 'qua quít',\n",
       " 'qua quýt',\n",
       " 'quyết',\n",
       " 'quyết nhiên',\n",
       " 'quyển',\n",
       " 'quá',\n",
       " 'quá chừng',\n",
       " 'quá lắm',\n",
       " 'quá sá',\n",
       " 'quá thể',\n",
       " 'quá trời',\n",
       " 'quá xá',\n",
       " 'quá đỗi',\n",
       " 'quá độ',\n",
       " 'quá ư',\n",
       " 'quý hồ',\n",
       " 'quả',\n",
       " 'quả là',\n",
       " 'quả tang',\n",
       " 'quả thật',\n",
       " 'quả tình',\n",
       " 'quả vậy',\n",
       " 'quả đúng',\n",
       " 'ra',\n",
       " 'ra phết',\n",
       " 'ra sao',\n",
       " 'ra trò',\n",
       " 'ren rén',\n",
       " 'riu ríu',\n",
       " 'riêng',\n",
       " 'riệt',\n",
       " 'rày',\n",
       " 'ráo',\n",
       " 'ráo trọi',\n",
       " 'rén',\n",
       " 'rích',\n",
       " 'rón rén',\n",
       " 'rút cục',\n",
       " 'răng',\n",
       " 'rất',\n",
       " 'rằng',\n",
       " 'rằng là',\n",
       " 'rốt cuộc',\n",
       " 'rốt cục',\n",
       " 'rồi',\n",
       " 'rứa',\n",
       " 'sa sả',\n",
       " 'sao',\n",
       " 'sau',\n",
       " 'sau chót',\n",
       " 'sau cuối',\n",
       " 'sau cùng',\n",
       " 'sau đó',\n",
       " 'so',\n",
       " 'song le',\n",
       " 'suýt',\n",
       " 'sì',\n",
       " 'sạch',\n",
       " 'sất',\n",
       " 'sắp',\n",
       " 'sẽ',\n",
       " 'số',\n",
       " 'số là',\n",
       " 'sốt sột',\n",
       " 'sở dĩ',\n",
       " 'sự',\n",
       " 'tanh',\n",
       " 'tha hồ',\n",
       " 'than ôi',\n",
       " 'thanh',\n",
       " 'theo',\n",
       " 'thi thoảng',\n",
       " 'thoạt',\n",
       " 'thoạt nhiên',\n",
       " 'thoắt',\n",
       " 'thuần',\n",
       " 'thà',\n",
       " 'thà là',\n",
       " 'thà rằng',\n",
       " 'thành ra',\n",
       " 'thành thử',\n",
       " 'thái quá',\n",
       " 'tháng',\n",
       " 'thì',\n",
       " 'thì thôi',\n",
       " 'thình lình',\n",
       " 'thím',\n",
       " 'thôi',\n",
       " 'thúng thắng',\n",
       " 'thương ôi',\n",
       " 'thường',\n",
       " 'thảo hèn',\n",
       " 'thảo nào',\n",
       " 'thấy',\n",
       " 'thẩy',\n",
       " 'thậm',\n",
       " 'thậm chí',\n",
       " 'thật lực',\n",
       " 'thật ra',\n",
       " 'thật vậy',\n",
       " 'thế',\n",
       " 'thế là',\n",
       " 'thế mà',\n",
       " 'thế nào',\n",
       " 'thế nên',\n",
       " 'thế ra',\n",
       " 'thế thì',\n",
       " 'thế à',\n",
       " 'thếch',\n",
       " 'thỉnh thoảng',\n",
       " 'thỏm',\n",
       " 'thốc',\n",
       " 'thốc tháo',\n",
       " 'thốt',\n",
       " 'thốt nhiên',\n",
       " 'thộc',\n",
       " 'thời gian',\n",
       " 'thục mạng',\n",
       " 'thửa',\n",
       " 'thực ra',\n",
       " 'thực sự',\n",
       " 'thực vậy',\n",
       " 'tiếp theo',\n",
       " 'tiếp đó',\n",
       " 'tiện thể',\n",
       " 'toà',\n",
       " 'toé khói',\n",
       " 'toẹt',\n",
       " 'trong',\n",
       " 'trên',\n",
       " 'trước',\n",
       " 'trước kia',\n",
       " 'trước nay',\n",
       " 'trước tiên',\n",
       " 'trước đây',\n",
       " 'trước đó',\n",
       " 'trếu tráo',\n",
       " 'trển',\n",
       " 'trệt',\n",
       " 'trệu trạo',\n",
       " 'trỏng',\n",
       " 'trời đất ơi',\n",
       " 'trừ phi',\n",
       " 'tuy',\n",
       " 'tuy nhiên',\n",
       " 'tuy rằng',\n",
       " 'tuy thế',\n",
       " 'tuy vậy',\n",
       " 'tuyệt nhiên',\n",
       " 'tuần tự',\n",
       " 'tuốt luốt',\n",
       " 'tuốt tuồn tuột',\n",
       " 'tuốt tuột',\n",
       " 'tà tà',\n",
       " 'tênh',\n",
       " 'tít mù',\n",
       " 'tò te',\n",
       " 'tôi',\n",
       " 'tông tốc',\n",
       " 'tù tì',\n",
       " 'tăm tắp',\n",
       " 'tại',\n",
       " 'tại vì',\n",
       " 'tấm',\n",
       " 'tấn',\n",
       " 'tất cả',\n",
       " 'tất thảy',\n",
       " 'tất tần tật',\n",
       " 'tất tật',\n",
       " 'tắp',\n",
       " 'tắp lự',\n",
       " 'tọt',\n",
       " 'tỏ ra',\n",
       " 'tỏ vẻ',\n",
       " 'tốc tả',\n",
       " 'tối ư',\n",
       " 'tột',\n",
       " 'tớ',\n",
       " 'tới',\n",
       " 'tức thì',\n",
       " 'tức tốc',\n",
       " 'từ',\n",
       " 'từng',\n",
       " 'tự vì',\n",
       " 'tựu trung',\n",
       " 'veo',\n",
       " 'veo veo',\n",
       " 'việc',\n",
       " 'vung thiên địa',\n",
       " 'vung tàn tán',\n",
       " 'vung tán tàn',\n",
       " 'và',\n",
       " 'vào',\n",
       " 'vâng',\n",
       " 'vèo',\n",
       " 'vì',\n",
       " 'vì chưng',\n",
       " 'vì thế',\n",
       " 'vì vậy',\n",
       " 'ví bằng',\n",
       " 'ví dù',\n",
       " 'ví phỏng',\n",
       " 'ví thử',\n",
       " 'vô hình trung',\n",
       " 'vô kể',\n",
       " 'vô luận',\n",
       " 'vô vàn',\n",
       " 'văng tê',\n",
       " 'vạn nhất',\n",
       " 'vả chăng',\n",
       " 'vả lại',\n",
       " 'vẫn',\n",
       " 'vậy',\n",
       " 'vậy là',\n",
       " 'vậy thì',\n",
       " 'về',\n",
       " 'vị tất',\n",
       " 'vốn dĩ',\n",
       " 'với',\n",
       " 'với lại',\n",
       " 'vở',\n",
       " 'vụt',\n",
       " 'vừa',\n",
       " 'vừa mới',\n",
       " 'xa xả',\n",
       " 'xiết bao',\n",
       " 'xon xón',\n",
       " 'xoành xoạch',\n",
       " 'xoét',\n",
       " 'xoẳn',\n",
       " 'xoẹt',\n",
       " 'xuất kì bất ý',\n",
       " 'xuất kỳ bất ý',\n",
       " 'xuể',\n",
       " 'xuống',\n",
       " 'xăm xúi',\n",
       " 'xăm xăm',\n",
       " 'xăm xắm',\n",
       " 'xềnh xệch',\n",
       " 'xệp',\n",
       " 'à',\n",
       " 'à ơi',\n",
       " 'ào',\n",
       " 'á',\n",
       " 'á à',\n",
       " 'ái',\n",
       " 'ái chà',\n",
       " 'ái dà',\n",
       " 'áng',\n",
       " 'âu là',\n",
       " 'ô hay',\n",
       " 'ô hô',\n",
       " 'ô kê',\n",
       " 'ô kìa',\n",
       " 'ôi chao',\n",
       " 'ôi thôi',\n",
       " 'ông',\n",
       " 'úi',\n",
       " 'úi chà',\n",
       " 'úi dào',\n",
       " 'ý',\n",
       " 'ý chừng',\n",
       " 'ý da',\n",
       " 'đang',\n",
       " 'đi',\n",
       " 'điều',\n",
       " 'đành đạch',\n",
       " 'đáng lí',\n",
       " 'đáng lý',\n",
       " 'đáng lẽ',\n",
       " 'đánh đùng',\n",
       " 'đáo để',\n",
       " 'đây',\n",
       " 'đã',\n",
       " 'đó',\n",
       " 'được',\n",
       " 'đại loại',\n",
       " 'đại nhân',\n",
       " 'đại phàm',\n",
       " 'đại để',\n",
       " 'đến',\n",
       " 'đến nỗi',\n",
       " 'đều',\n",
       " 'để',\n",
       " 'ơ',\n",
       " 'ơ hay',\n",
       " 'ơ kìa',\n",
       " 'ơi',\n",
       " 'ư',\n",
       " 'ạ',\n",
       " 'ạ ơi',\n",
       " 'ấy',\n",
       " 'ầu ơ',\n",
       " 'ắt',\n",
       " 'ắt hẳn',\n",
       " 'ắt là',\n",
       " 'ối dào',\n",
       " 'ối giời',\n",
       " 'ối giời ơi',\n",
       " 'ồ',\n",
       " 'ổng',\n",
       " 'ớ',\n",
       " 'ờ',\n",
       " 'ở',\n",
       " 'ở trên',\n",
       " 'ủa',\n",
       " 'ứ hự',\n",
       " 'ứ ừ',\n",
       " 'ừ',\n",
       " 'ử'}"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Cập nhật lại hàm `word_counts` thêm chức năng loại bỏ stopword như sau:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "en_sw = stopwords.stopwords('en')\n",
    "def word_counts(x, pipeline=en):\n",
    "    doc = pipeline(x)\n",
    "    cnt = 0\n",
    "    \n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            if token.text.lower() not in en_sw:\n",
    "                cnt += 1\n",
    "                \n",
    "    return cnt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "train['Words'] = train['Message'].apply(word_counts)\n",
    "test['Words'] = test['Message'].apply(word_counts)\n",
    "\n",
    "x_train = train[['Words', 'Capitals', 'Punctuation', 'Length']]\n",
    "y_train = train[['Spam']]\n",
    "\n",
    "x_test = test[['Words', 'Capitals', 'Punctuation', 'Length']]\n",
    "y_test = test[['Spam']]\n",
    "\n",
    "model = make_model(input_dims=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.6630 - accuracy: 0.8210\n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.4092 - accuracy: 0.8713\n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.3066 - accuracy: 0.9087\n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2497 - accuracy: 0.9258\n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2196 - accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.2034 - accuracy: 0.9368\n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9368\n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.1832 - accuracy: 0.9394\n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.9374\n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 1s 1ms/step - loss: 0.1737 - accuracy: 0.9433\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc27aebea30>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "train.loc[train.Spam == 1].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Spam    Capitals  Punctuation      Length       Words\n",
       "count  592.0  592.000000   592.000000  592.000000  592.000000\n",
       "mean     1.0   15.320946    29.086149  138.856419   18.464527\n",
       "std      0.0   11.635105     7.083572   28.079980    6.100852\n",
       "min      1.0    0.000000     2.000000   13.000000    2.000000\n",
       "25%      1.0    7.000000    26.000000  132.000000   14.000000\n",
       "50%      1.0   14.000000    30.000000  149.000000   19.000000\n",
       "75%      1.0   21.000000    34.000000  157.000000   23.000000\n",
       "max      1.0  128.000000    49.000000  197.000000   33.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.0</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.320946</td>\n",
       "      <td>29.086149</td>\n",
       "      <td>138.856419</td>\n",
       "      <td>18.464527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.635105</td>\n",
       "      <td>7.083572</td>\n",
       "      <td>28.079980</td>\n",
       "      <td>6.100852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "train.loc[train.Spam == 0].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Spam     Capitals  Punctuation       Length        Words\n",
       "count  3867.0  3867.000000  3867.000000  3867.000000  3867.000000\n",
       "mean      0.0     4.018878    17.325058    71.354538     7.911042\n",
       "std       0.0    10.599291    14.826644    57.755351     7.326390\n",
       "min       0.0     0.000000     0.000000     2.000000     0.000000\n",
       "25%       0.0     1.000000     8.000000    33.000000     4.000000\n",
       "50%       0.0     2.000000    13.000000    53.000000     6.000000\n",
       "75%       0.0     3.000000    23.000000    92.000000    10.000000\n",
       "max       0.0   129.000000   253.000000   910.000000   147.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Capitals</th>\n",
       "      <th>Punctuation</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3867.0</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "      <td>3867.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.018878</td>\n",
       "      <td>17.325058</td>\n",
       "      <td>71.354538</td>\n",
       "      <td>7.911042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.599291</td>\n",
       "      <td>14.826644</td>\n",
       "      <td>57.755351</td>\n",
       "      <td>7.326390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "model.evaluate(x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9300\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.20706488192081451, 0.9300448298454285]"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}